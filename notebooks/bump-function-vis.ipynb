{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "## vis\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3562ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, a, mu):\n",
    "    '''UMAP-inspired predict function\n",
    "    x - torch tensor, shape [n_data_points, n_features]\n",
    "    a - torch tensor, shape [n_features]\n",
    "        1/a.abs() is the extent of bounding box at prediction=0.5\n",
    "    mu - torch tensor, shape [n_features]\n",
    "    b - scalar. hyper parameter for predict function. Power exponent\n",
    "    '''\n",
    "\n",
    "    b = 3\n",
    "    return 1 / (1 + ((a.abs() * (x - mu).abs()).pow(b)).sum(1))\n",
    "\n",
    "# test: UMAP-inspired predict function\n",
    "# n = 100\n",
    "# x = torch.linspace(-3,3,n).view(n,1)\n",
    "# a = torch.tensor(0.5)\n",
    "# plt.plot(x, predict(x, a))\n",
    "\n",
    "\n",
    "def compute_predicate(x0, selected, n_iter=1000, mu_init=None, a_init=0.4):\n",
    "    '''\n",
    "        x0 - numpy array, shape=[n_points, n_feature]. Data points\n",
    "        selected - boolean array. shape=[n_points] of selection\n",
    "    '''\n",
    "\n",
    "    # prepare training data\n",
    "    # orginal data extent\n",
    "    n_points, n_features = x0.shape\n",
    "    vmin = x0.min(0)\n",
    "    vmax = x0.max(0)\n",
    "    x = torch.from_numpy(x0.astype(np.float32))\n",
    "    label = torch.from_numpy(selected).float()\n",
    "    # normalize\n",
    "    mean = x.mean(0)\n",
    "    scale = x.std(0) + 0.1\n",
    "    x = (x - mean) / scale\n",
    "\n",
    "    # Trainable parameters\n",
    "    # since data is normalized,\n",
    "    # mu can initialized around mean_pos examples\n",
    "    # a can initialized around a constant across all axes\n",
    "    center_selected = x[selected].mean(0)\n",
    "    if mu_init is None:\n",
    "        mu_init = center_selected\n",
    "    a = (a_init + 0.1*(2*torch.rand(n_features)-1))\n",
    "    mu = mu_init + 0.1 * (2*torch.rand(x.shape[1]) - 1)\n",
    "    a.requires_grad_(True)\n",
    "    mu.requires_grad_(True)\n",
    "\n",
    "    # weight-balance selected vs. unselected based on their size\n",
    "    n_selected = selected.sum()\n",
    "    n_unselected = n_points - n_selected\n",
    "    instance_weight = torch.ones(x.shape[0])\n",
    "    instance_weight[selected] = n_points/n_selected\n",
    "    instance_weight[~selected] = n_points/n_unselected\n",
    "    bce = nn.BCELoss(weight=instance_weight)\n",
    "    optimizer = optim.SGD([\n",
    "        {'params': mu, 'weight_decay': 0},\n",
    "        # smaller a encourages larger reach of the bounding box\n",
    "        {'params': a, 'weight_decay': 0.01}\n",
    "    ], lr=1e-2, momentum=0.9)\n",
    "\n",
    "    # training loop\n",
    "    for e in range(n_iter):\n",
    "        pred = predict(x, a, mu)\n",
    "        loss = bce(pred, label)\n",
    "        loss += (mu - center_selected).pow(2).mean() * 20\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if e % (n_iter//5) == 0:\n",
    "            # print(pred.min().item(), pred.max().item())\n",
    "            print(f'[{e:>4}] loss {loss.item()}')\n",
    "    a.detach_()\n",
    "    mu.detach_()\n",
    "    # plt.stem(a.abs().numpy()); plt.show()\n",
    "\n",
    "    pred = (pred > 0.5).float()\n",
    "    correct = (pred == label).float().sum().item()\n",
    "    total = selected.shape[0]\n",
    "    accuracy = correct/total\n",
    "    # 1 meaning points are selected\n",
    "    tp = ((pred == 1).float() * (label == 1).float()).sum().item()\n",
    "    fp = ((pred == 1).float() * (label == 0).float()).sum().item()\n",
    "    fn = ((pred == 0).float() * (label == 1).float()).sum().item()\n",
    "    precision = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 1/(1/precision + 1/recall)\n",
    "    print(f'''\n",
    "accuracy = {correct/total}\n",
    "precision = {precision}\n",
    "recall = {recall}\n",
    "f1 = {f1}\n",
    "    ''')\n",
    "\n",
    "    # predicate clause selection\n",
    "    # r is the range of the bounding box on each dimension\n",
    "    # bounding box is defined by the level set of prediction=0.5\n",
    "    r = 1 / a.abs()\n",
    "    predicates = []\n",
    "    for k in range(mu.shape[0]):\n",
    "        # denormalize\n",
    "        r_k = (r[k] * scale[k]).item()\n",
    "        mu_k = (mu[k] * scale[k] + mean[k]).item()\n",
    "        ci = [mu_k - r_k, mu_k + r_k]\n",
    "        assert ci[0] < ci[1], 'ci[0] is not less than ci[1]'\n",
    "        if ci[0] < vmin[k]:\n",
    "            ci[0] = vmin[k]\n",
    "        if ci[1] > vmax[k]:\n",
    "            ci[1] = vmax[k]\n",
    "        # feature selection based on extent range\n",
    "#         should_include = r[k] < 1.0 * (x[:,k].max()-x[:,k].min())\n",
    "        should_include = not (ci[0] <= vmin[k] and ci[1] >= vmax[k])\n",
    "        if should_include:\n",
    "            predicates.append(dict(\n",
    "                dim=k, interval=ci\n",
    "            ))\n",
    "    for p in predicates:\n",
    "        print(p)\n",
    "    return predicates, mu, a, [accuracy, precision, recall, f1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfde339e",
   "metadata": {},
   "source": [
    "## predicate test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22180c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(f'./dataset/animals3.csv')\n",
    "# for attr in ['x', 'y', 'image_filename']:\n",
    "#     if attr in df.columns:\n",
    "#         df = df.drop(attr, axis='columns')\n",
    "# x0 = df.to_numpy()\n",
    "\n",
    "# ## simulate a sequence of brushes\n",
    "# t = 5\n",
    "# selected = np.zeros([t,x0.shape[0]]).astype(np.bool8)\n",
    "# selected[0, df['big eyes']<0.17] = 1\n",
    "# selected[1, df['big eyes']<0.18] = 1\n",
    "# selected[2, df['big eyes']<0.19] = 1\n",
    "# selected[3, df['big eyes']<0.20] = 1\n",
    "# selected[4, df['big eyes']<0.21] = 1\n",
    "# print('selected', selected.sum(1), 'points in the sequence...')\n",
    "\n",
    "# for i in range(5):\n",
    "#     predicate, mu, a, quality = compute_predicate(x0, selected[i], n_iter=1000, mu_init=None, a_init=0.4)\n",
    "# # predicate, mu, a, quality = compute_predicate_sequence(x0, selected, n_iter=1000, mu_init=None, a_init=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853f23c",
   "metadata": {},
   "source": [
    "## Predicate sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0f082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28501bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(x, a, mu):\n",
    "#     '''UMAP-inspired predict function\n",
    "#     x - torch tensor, shape [n_data_points, n_features]\n",
    "#     a - torch tensor, shape [n_features]\n",
    "#         1/a.abs() is the extent of bounding box at prediction=0.5\n",
    "#     mu - torch tensor, shape [n_features]\n",
    "#     b - scalar. hyper parameter for predict function. Power exponent\n",
    "#     '''\n",
    "\n",
    "#     b = 3\n",
    "#     return 1 / (1 + ((a.abs() * (x - mu).abs()).pow(b)).sum(1))\n",
    "\n",
    "# # test: UMAP-inspired predict function\n",
    "# # n = 100\n",
    "# # x = torch.linspace(-3,3,n).view(n,1)\n",
    "# # a = torch.tensor(0.5)\n",
    "# # plt.plot(x, predict(x, a))\n",
    "\n",
    "\n",
    "# def compute_predicate_sequence(x0, selected, n_iter=1000):\n",
    "#     '''\n",
    "#         x0 - numpy array, shape=[n_points, n_feature]. Data points\n",
    "#         selected - boolean array. shape=[brush_index, n_points] of selection\n",
    "#     '''\n",
    "#     mu_init=None\n",
    "#     a_init=0.4\n",
    "    \n",
    "#     n_points, n_features = x0.shape\n",
    "#     n_brushes = selected.shape[0]\n",
    "    \n",
    "#     # prepare training data\n",
    "#     # orginal data extent\n",
    "#     vmin = x0.min(0)\n",
    "#     vmax = x0.max(0)\n",
    "#     x = torch.from_numpy(x0.astype(np.float32))\n",
    "#     label = torch.from_numpy(selected).float()\n",
    "#     # normalize\n",
    "#     mean = x.mean(0)\n",
    "#     scale = x.std(0) + 0.1\n",
    "#     x = (x - mean) / scale\n",
    "\n",
    "#     # Trainable parameters\n",
    "#     # since data is normalized,\n",
    "#     # mu can initialized around mean_pos examples\n",
    "#     # a can initialized around a constant across all axes\n",
    "#     selection_centroids = torch.stack([x[sel_t].mean(0) for sel_t in selected], 0)\n",
    "\n",
    "#     if mu_init is None:\n",
    "#         mu_init = selection_centroids\n",
    "#     a = (a_init + 0.1*(2*torch.rand(n_brushes, n_features)-1))\n",
    "#     mu = mu_init + 0.1 * (2*torch.rand(n_brushes, x.shape[1]) - 1)\n",
    "#     a.requires_grad_(True)\n",
    "#     mu.requires_grad_(True)\n",
    "\n",
    "#     # weight-balance selected vs. unselected based on their size\n",
    "#     bce_per_brush = []\n",
    "#     for st in selected: ## for each brush, define their class-balanced loss function\n",
    "#         n_selected = st.sum()\n",
    "#         n_unselected = n_points - n_selected\n",
    "#         instance_weight = torch.ones(x.shape[0])\n",
    "#         instance_weight[st] = n_points/n_selected\n",
    "#         instance_weight[~st] = n_points/n_unselected\n",
    "#         bce = nn.BCELoss(weight=instance_weight)\n",
    "#         bce_per_brush.append(bce)\n",
    "    \n",
    "    \n",
    "#     optimizer = optim.SGD([\n",
    "#         {'params': mu, 'weight_decay': 0},\n",
    "#         # smaller a encourages larger reach of the bounding box\n",
    "#         {'params': a, 'weight_decay': 0.01}\n",
    "#     ], lr=1e-2, momentum=0.9)\n",
    "\n",
    "#     # training loop\n",
    "#     for e in range(n_iter):\n",
    "#         loss_per_brush = []\n",
    "#         for t, st in enumerate(selected): ## for each brush, compute loss\n",
    "#             pred = predict(x, a[t], mu[t])\n",
    "#             loss = bce(pred, label[t])\n",
    "#             loss += (mu[t] - selection_centroids[t]).pow(2).mean() * 20\n",
    "#             loss_per_brush.append(loss)\n",
    "#         smoothness_loss = 100 * (a[1:]-a[:-1]).pow(2).mean()\n",
    "#         smoothness_loss += 100 * (mu[1:]-mu[:-1]).pow(2).mean()\n",
    "        \n",
    "#         total_loss = sum(loss_per_brush) + smoothness_loss\n",
    "#         optimizer.zero_grad()\n",
    "#         total_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if e % (n_iter//5) == 0:\n",
    "#             # print(pred.min().item(), pred.max().item())\n",
    "#             print(f'[{e:>4}] loss {loss.item()}')\n",
    "#     a.detach_()\n",
    "#     mu.detach_()\n",
    "#     # plt.stem(a.abs().numpy()); plt.show()\n",
    "\n",
    "#     qualities = []\n",
    "#     for t, st in enumerate(selected): ## for each brush, compute loss\n",
    "#         pred = predict(x, a[t], mu[t])\n",
    "#         pred = (pred > 0.5).float()\n",
    "#         correct = (pred == label[t]).float().sum().item()\n",
    "#         total = n_points\n",
    "#         accuracy = correct/total\n",
    "#         # 1 meaning points are selected\n",
    "#         tp = ((pred == 1).float() * (label == 1).float()).sum().item()\n",
    "#         fp = ((pred == 1).float() * (label == 0).float()).sum().item()\n",
    "#         fn = ((pred == 0).float() * (label == 1).float()).sum().item()\n",
    "#         precision = tp/(tp+fp)\n",
    "#         recall = tp/(tp+fn)\n",
    "#         f1 = 1/(1/precision + 1/recall)\n",
    "#         print(dedent(f'''\n",
    "#             brush = {t}\n",
    "#             accuracy = {accuracy}\n",
    "#             precision = {precision}\n",
    "#             recall = {recall}\n",
    "#             f1 = {f1}\n",
    "#         '''))\n",
    "#         qualities.append(dict(\n",
    "#             brush = t,\n",
    "#             accuracy = accuracy,\n",
    "#             precision = precision,\n",
    "#             recall = recall,\n",
    "#             f1 = f1\n",
    "#         ))\n",
    "\n",
    "#     # predicate clause selection\n",
    "#     # r is the range of the bounding box on each dimension\n",
    "#     # bounding box is defined by the level set of prediction=0.5\n",
    "#     predicates = []\n",
    "#     for t, st in enumerate(selected): ## for each brush, generate a predicate from a[t] and mu[t]\n",
    "#         r = 1 / a[t].abs()\n",
    "#         predicate_clauses = []\n",
    "#         for k in range(n_features): # for each attribute\n",
    "#             # denormalize\n",
    "#             r_k = (r[k] * scale[k]).item()\n",
    "#             mu_k = (mu[t,k] * scale[k] + mean[k]).item()\n",
    "#             ci = [mu_k - r_k, mu_k + r_k]\n",
    "#             assert ci[0] < ci[1], 'ci[0] is not less than ci[1]'\n",
    "#             if ci[0] < vmin[k]:\n",
    "#                 ci[0] = vmin[k]\n",
    "#             if ci[1] > vmax[k]:\n",
    "#                 ci[1] = vmax[k]\n",
    "#             # feature selection based on extent range\n",
    "#     #         should_include = r[k] < 1.0 * (x[:,k].max()-x[:,k].min())\n",
    "#             should_include = not (ci[0] <= vmin[k] and ci[1] >= vmax[k])\n",
    "#             if should_include:\n",
    "#                 predicate_clauses.append(dict(\n",
    "#                     dim=k, interval=ci\n",
    "#                 ))\n",
    "#         predicates.append(predicate_clauses)\n",
    "#     parameters = dict(mu=mu, a=a)\n",
    "#     return predicates, qualities, parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51deb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(f'./dataset/animals3.csv')\n",
    "# for attr in ['x', 'y', 'image_filename']:\n",
    "#     if attr in df.columns:\n",
    "#         df = df.drop(attr, axis='columns')\n",
    "# x0 = df.to_numpy()\n",
    "\n",
    "# ## simulate a sequence of brushes\n",
    "# t = 5\n",
    "# selected = np.zeros([t,x0.shape[0]]).astype(np.bool8)\n",
    "# selected[0, df['big eyes']<0.17] = 1\n",
    "# selected[1, df['big eyes']<0.18] = 1\n",
    "# selected[2, df['big eyes']<0.19] = 1\n",
    "# selected[3, df['big eyes']<0.20] = 1\n",
    "# selected[4, df['big eyes']<0.21] = 1\n",
    "# print('selected', selected.sum(1), 'points in the sequence...')\n",
    "\n",
    "# predicates, qualities, parameters = compute_predicate_sequence(x0, selected, n_iter=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c533aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b = 3\n",
    "# def predict(x, a, mu=0):\n",
    "#     '''\n",
    "#     x - torch tensor with shape [n_data_points, n_features]\n",
    "#     a - torch tensor with shape [n_features]\n",
    "#     '''\n",
    "#     return 1 / (1 + ((a.abs() * (x - mu).abs()).pow(b)).sum(1))\n",
    "\n",
    "# ## test UMAP-inspired predict function\n",
    "# # n = 100\n",
    "# # x = torch.linspace(-3,3,n).view(n,1)\n",
    "# # a = torch.tensor(0.5)\n",
    "# # plt.plot(x, predict(x, a))\n",
    "\n",
    "\n",
    "# def predicate(x0, selected, n_iter=3000):\n",
    "#     '''\n",
    "#         x0 - numpy array. data points\n",
    "#         selected - boolean array of selection\n",
    "#     '''\n",
    "#     # prepare training data\n",
    "#     x = torch.from_numpy(x0.astype(np.float32))\n",
    "#     label = torch.from_numpy(selected).float()\n",
    "    \n",
    "#     # normalize\n",
    "#     mean = x.mean(0)\n",
    "#     scale = x.std(0) + 0.1\n",
    "#     x = (x - mean) / scale\n",
    "\n",
    "#     bce = nn.BCELoss()\n",
    "    \n",
    "#     ## since data is normalized, \n",
    "#     ## mu can initialized around mean_pos examples\n",
    "#     ## a can initialized around a constant across all axes\n",
    "#     mu_init = x[selected].mean(0)\n",
    "#     a_init = 0.4\n",
    "    \n",
    "#     a = (a_init + 0.1*(2*torch.rand(x.shape[1])-1)).requires_grad_(True)\n",
    "#     mu = mu_init + 0.1 * (2*torch.rand(x.shape[1]) - 1)\n",
    "#     mu.requires_grad_(True)\n",
    "#     optimizer = optim.SGD([\n",
    "#         {'params': mu, 'weight_decay': 0},\n",
    "#         {'params': a, 'weight_decay': 0.01} ## smaller a encourages larger reach of the bounding box\n",
    "#     ], lr=1e-2, momentum=0.9)\n",
    "#     for e in range(n_iter):\n",
    "#         pred = predict(x, a, mu)\n",
    "#         l = bce(pred, label)\n",
    "#         optimizer.zero_grad()\n",
    "#         l.backward()\n",
    "#         optimizer.step()\n",
    "#         if e % (n_iter//5) == 0:\n",
    "#             print('loss', l.item())\n",
    "#     a.detach_()\n",
    "#     mu.detach_()\n",
    "\n",
    "# #     plt.stem(a.abs().numpy())\n",
    "# #     plt.show()\n",
    "    \n",
    "#     ## range of the bounding box, defined by the level set of prediction=0.5\n",
    "#     r = 1 / a.abs()\n",
    "    \n",
    "#     print(\n",
    "#         'accuracy',\n",
    "#         ((pred > 0.5).float() == label).float().sum().item(),\n",
    "#         '/', selected.shape[0])\n",
    "\n",
    "    \n",
    "#     ## orginal data extent\n",
    "#     vmin = x0.min(0)\n",
    "#     vmax = x0.max(0)\n",
    "    \n",
    "#     ##predicate clause selection\n",
    "#     predicates = []\n",
    "#     for k in range(mu.shape[0]):\n",
    "        \n",
    "#         ## denormalize\n",
    "#         r_k = (r[k] * scale[k]).item()\n",
    "#         mu_k = (mu[k] * scale[k] + mean[k]).item()\n",
    "#         ci = ((mu_k - r_k), (mu_k + r_k))\n",
    "        \n",
    "        \n",
    "#         ## feature selection based on extent range\n",
    "# #         should_include = r[k] < 1.0 * (x[:,k].max()-x[:,k].min())\n",
    "#         should_include = not (ci[0] < vmin[k] and ci[1] > vmax[k])\n",
    "#         if should_include: \n",
    "#             predicates.append(dict(\n",
    "#                 dim=k, interval=[max(ci[0],vmin[k]), min(ci[1], vmax[k])]\n",
    "#             ))\n",
    "#     return predicates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b3801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test, 2D dataset\n",
    "# data = np.random.rand(150,2)\n",
    "\n",
    "# target = (\n",
    "#     (0.3<data[:,0])*(data[:,0]<0.6)\n",
    "#     *(0<data[:,1])*(data[:,1]<0.5)\n",
    "# ).astype(np.int64)\n",
    "# target = ((0.3<data[:,0])*(data[:,0]<0.6)).astype(np.int64)\n",
    "\n",
    "# for i in range(10):\n",
    "#     p = predicate(data, target)\n",
    "#     display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fde644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 7\n",
    "def predict(x, a, mu=0):\n",
    "    '''\n",
    "    x - torch tensor with shape [n_data_points, n_features]\n",
    "    a - torch tensor with shape [n_features]\n",
    "    '''\n",
    "    return 1 / (1 + ((a.abs() * (x - mu).abs()).pow(b)).sum(1))\n",
    "\n",
    "# def predict_gaussian(x, mu=0, b=2):\n",
    "#     print(x.shape)\n",
    "#     return torch.exp(-(x-mu).pow(b).sum(1))\n",
    "\n",
    "gx, gy = torch.meshgrid(torch.linspace(-4,4,65), torch.linspace(-4,4,65), indexing='xy')\n",
    "xy = torch.stack([gx.reshape(-1), gy.reshape(-1)], dim=1)\n",
    "z = predict(xy, a=torch.tensor([1/1,1/2])).reshape([65,65])\n",
    "# z = predict_gaussian(xy, b=4).reshape([40,40])\n",
    "\n",
    "gx = gx.numpy()\n",
    "gy = gy.numpy()\n",
    "z = z.numpy()\n",
    "\n",
    "plt.figure(figsize=[4,4])\n",
    "plt.contour(gx, gy, z, levels=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "plt.axis('square');\n",
    "\n",
    "plt.figure(figsize=[4,2])\n",
    "plt.plot(gx[0], z[10]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3a7b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install chart-studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026dca98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14808d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeca99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_verts(cn):\n",
    "    contours = []\n",
    "    # for each contour line\n",
    "    for cc in cn.collections:\n",
    "        paths = []\n",
    "        # for each separate section of the contour line\n",
    "        for pp in cc.get_paths():\n",
    "            xy = []\n",
    "            # for each segment of that section\n",
    "            for vv in pp.iter_segments():\n",
    "                xy.append(vv[0])\n",
    "            paths.append(np.vstack(xy))\n",
    "        contours.append(paths)\n",
    "\n",
    "    return contours\n",
    "\n",
    "cn = plt.contour(gx, gy, z, levels=[0.5])\n",
    "contour_verts_2d = get_contour_verts(cn)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b25569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb31b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24ad27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors\n",
    "# '#C2C973'=muted yellow\n",
    "# '#1f78b4' C0 blue\n",
    "surface_color = '#7B3F00'  \n",
    "wireframe_color = '#7B3F00'\n",
    "predicate_line_color = '#333'\n",
    "pos_point_color = '#fff'\n",
    "neg_point_color = '#fff'\n",
    "\n",
    "\n",
    "# Creating the lines\n",
    "lines = []\n",
    "line_marker = dict(color=surface_color, width=1, )\n",
    "skip = 8\n",
    "for i, j, k in zip(gx[::skip], gy[::skip], z[::skip]):\n",
    "    lines.append(go.Scatter3d(x=i, y=j, z=k, mode='lines', line=line_marker, opacity=0.5))\n",
    "for i, j, k in zip(gx.T[::skip], gy.T[::skip], z.T[::skip]):\n",
    "    lines.append(go.Scatter3d(x=i, y=j, z=k, mode='lines', line=line_marker, opacity=0.5))\n",
    "    \n",
    "\n",
    "# lines for the predicate range\n",
    "zp = 0.005\n",
    "predicate_line_style = dict(color=predicate_line_color, width=3, dash = 'dash')\n",
    "lines.append(go.Scatter3d(x=[-1,-1], y=[-4,4], z=[zp,zp], mode='lines', line=predicate_line_style))\n",
    "lines.append(go.Scatter3d(x=[1,1], y=[-4,4], z=[zp,zp], mode='lines', line=predicate_line_style))\n",
    "lines.append(go.Scatter3d(x=[-4,4], y=[-2,-2], z=[zp,zp], mode='lines', line=predicate_line_style))\n",
    "lines.append(go.Scatter3d(x=[-4,4], y=[2,2], z=[zp,zp], mode='lines', line=predicate_line_style))\n",
    "\n",
    "\n",
    "# contour lines\n",
    "contour_line_style = dict(color='yellow', width=5)\n",
    "lines.append(go.Scatter3d(\n",
    "    x=contour_verts_2d[:,0], \n",
    "    y=contour_verts_2d[:,1], \n",
    "    z=np.zeros(contour_verts_2d.shape[0])+0.001, \n",
    "    mode='lines', line=contour_line_style,\n",
    "    name='contour_floor'\n",
    "))\n",
    "lines.append(go.Scatter3d(\n",
    "    x=contour_verts_2d[:,0], \n",
    "    y=contour_verts_2d[:,1], \n",
    "    z=np.zeros(contour_verts_2d.shape[0])+0.5, \n",
    "    mode='lines', line=contour_line_style,\n",
    "    name='0.5 level set'\n",
    "))\n",
    "\n",
    "\n",
    "# Layout (Plotly)\n",
    "layout = go.Layout(\n",
    "    title='Predicate proxy function',\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            gridcolor='rgb(255, 255, 255)',\n",
    "            zerolinecolor='rgb(255, 255, 255)',\n",
    "            showbackground=True,\n",
    "            backgroundcolor='rgb(230, 230, 230)'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            gridcolor='rgb(255, 255, 255)',\n",
    "            zerolinecolor='rgb(255, 255, 255)',\n",
    "            showbackground=True,\n",
    "            backgroundcolor='rgb(230, 230, 230)'\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            gridcolor='rgb(255, 255, 255)',\n",
    "            zerolinecolor='rgb(255, 255, 255)',\n",
    "            showbackground=True,\n",
    "            backgroundcolor='rgb(230, 230, 230)',\n",
    "            nticks=4, \n",
    "            range=[0,1.05],\n",
    "        )\n",
    "        \n",
    "    ),\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "# scatter plot\n",
    "pos = (np.random.rand(20,2)-0.5)*2*[0.5,1]\n",
    "neg = (np.random.rand(50,2)-0.5)*2*4\n",
    "neg = neg[~np.logical_and(np.abs(neg[:,0])<1.3, np.abs(neg[:,1])<2)]\n",
    "names = [\"Pattern Points (P)\", 'Background Points (B)', '0.5 level set']\n",
    "scatter_pos = go.Scatter3d(\n",
    "    name=names[0],\n",
    "    x=pos[:,0],\n",
    "    y=pos[:,1],\n",
    "    z=np.ones(pos.shape[0])+0.01, \n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[pos_point_color]*pos.shape[0],\n",
    "        symbol=['circle']*pos.shape[0],\n",
    "        size=[10]*pos.shape[0],\n",
    "        line_width=0,\n",
    "        opacity=1.0,\n",
    "    )\n",
    ")\n",
    "scatter_neg = go.Scatter3d(\n",
    "    name=names[1],\n",
    "    x=neg[:,0],\n",
    "    y=neg[:,1],\n",
    "    z=np.zeros(neg.shape[0])+0.05, \n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=[neg_point_color,]*neg.shape[0],\n",
    "        symbol=['x',]*neg.shape[0],\n",
    "        size=[6,]*neg.shape[0],\n",
    "        line_width=0,\n",
    "        opacity=1.0,\n",
    "    )\n",
    ")\n",
    "\n",
    "# bump function surface, and contour\n",
    "colorscale = [\n",
    "    [0, surface_color], \n",
    "    [1, surface_color], \n",
    "]\n",
    "surface = go.Surface(\n",
    "    z=z, x=gx, y=gy, \n",
    "    opacity=0.5, \n",
    "    showscale=False,\n",
    "    colorscale=colorscale,\n",
    "    surfacecolor=np.ones_like(z),\n",
    "    lighting=dict(ambient=0.8, roughness=1.0),\n",
    "#     contours_z=dict(\n",
    "#         show=False, \n",
    "#         width=4, #not working\n",
    "#         start=0.5, end=0.6, size=0.25,\n",
    "#         usecolormap=False,\n",
    "#         color='midnightblue',\n",
    "#         highlightcolor=\"limegreen\", \n",
    "#         project_z=True,\n",
    "#     )\n",
    ")\n",
    "\n",
    "\n",
    "# assemble the figure\n",
    "fig = go.Figure(\n",
    "    data=[surface,\n",
    "        scatter_pos, \n",
    "        scatter_neg,\n",
    "        *lines\n",
    "    ], \n",
    "    layout=layout\n",
    ")\n",
    "\n",
    "# aspect ratio\n",
    "fig.update_scenes(\n",
    "    aspectmode='manual', \n",
    "    aspectratio=dict(x=1,y=1,z=0.3)\n",
    ")\n",
    "\n",
    "# axis labels\n",
    "fig.update_layout(\n",
    "    scene = dict(\n",
    "        xaxis_title='x1',\n",
    "        yaxis_title='x2',\n",
    "        zaxis_title='f(x1, x2)'\n",
    "    ),\n",
    "#     margin=dict(r=20, b=10, l=10, t=10)\n",
    ")\n",
    "\n",
    "# legends\n",
    "fig.update_layout(\n",
    "    showlegend=True,\n",
    "    legend=dict(\n",
    "        xanchor=\"left\",\n",
    "        yanchor=\"top\",\n",
    "        x=0.04,\n",
    "        y=0.70,\n",
    "        bgcolor='#e6e6e6',\n",
    "    )\n",
    ")\n",
    "for trace in fig['data']: \n",
    "#     print(trace['name'])\n",
    "    if (not trace['name'] in names):\n",
    "        trace['showlegend'] = False\n",
    "\n",
    "# camera\n",
    "camera = dict(\n",
    "    up=dict(x=0, y=0, z=1),\n",
    "    center=dict(x=0, y=0, z=0),\n",
    "    eye=dict(x=-1.5, y=1.25, z=0.5)\n",
    ")\n",
    "fig.update_layout(scene_camera=camera)\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa3091",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"fig1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ed184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig['data'][1]['name']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
