{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d31ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4349591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "## vis\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef61f2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 3\n",
    "def predict(x, a, mu=0):\n",
    "    '''\n",
    "    x - torch tensor with shape [n_data_points, n_features]\n",
    "    a - torch tensor with shape [n_features]\n",
    "    '''\n",
    "    return 1 / (1 + ((a.abs() * (x - mu).abs()).pow(b)).sum(1))\n",
    "\n",
    "## test UMAP-inspired predict function\n",
    "# n = 100\n",
    "# x = torch.linspace(-3,3,n).view(n,1)\n",
    "# a = torch.tensor(0.5)\n",
    "# plt.plot(x, predict(x, a))\n",
    "\n",
    "\n",
    "def predicate(x0, selected, n_iter=3000):\n",
    "    '''\n",
    "        x0 - data points\n",
    "        selected - boolean array of selection\n",
    "    '''\n",
    "    # prepare training data\n",
    "    x = torch.from_numpy(x0.astype(np.float32))\n",
    "    label = torch.from_numpy(selected).float()\n",
    "    \n",
    "    # normalize\n",
    "    mean = x.mean(0)\n",
    "    scale = x.std(0) + 0.1\n",
    "    x = (x - mean) / scale\n",
    "\n",
    "    bce = nn.BCELoss()\n",
    "    \n",
    "    ## since data is normalized, \n",
    "    ## mu can initialized around mean_pos examples\n",
    "    ## a can initialized around a constant across all axes\n",
    "    mu_init = x[selected].mean(0)\n",
    "    a_init = 0.4\n",
    "    \n",
    "    a = (a_init + 0.1*(2*torch.rand(x.shape[1])-1)).requires_grad_(True)\n",
    "    mu = mu_init + 0.1 * (2*torch.rand(x.shape[1]) - 1)\n",
    "    mu.requires_grad_(True)\n",
    "    optimizer = optim.SGD([\n",
    "        {'params': mu, 'weight_decay': 0},\n",
    "        {'params': a, 'weight_decay': 0.01} ## smaller a encourages larger reach of the bounding box\n",
    "    ], lr=1e-2, momentum=0.9)\n",
    "    for e in range(n_iter):\n",
    "        pred = predict(x, a, mu)\n",
    "        l = bce(pred, label)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        if e % (n_iter//5) == 0:\n",
    "            print('loss', l.item())\n",
    "    a.detach_()\n",
    "    mu.detach_()\n",
    "\n",
    "#     plt.stem(a.abs().numpy())\n",
    "#     plt.show()\n",
    "    \n",
    "    ## range of the bounding box, defined by the level set of prediction=0.5\n",
    "    r = 1 / a.abs()\n",
    "    \n",
    "    print(\n",
    "        'accuracy',\n",
    "        ((pred > 0.5).float() == label).float().sum().item(),\n",
    "        '/', selected.shape[0])\n",
    "\n",
    "    \n",
    "    ## orginal data extent\n",
    "    vmin = x0.min(0)\n",
    "    vmax = x0.max(0)\n",
    "    \n",
    "    ##predicate clause selection\n",
    "    predicates = []\n",
    "    for k in range(mu.shape[0]):\n",
    "        \n",
    "        ## denormalize\n",
    "        r_k = (r[k] * scale[k]).item()\n",
    "        mu_k = (mu[k] * scale[k] + mean[k]).item()\n",
    "        ci = ((mu_k - r_k), (mu_k + r_k))\n",
    "        \n",
    "        \n",
    "        ## feature selection based on extent range\n",
    "#         should_include = r[k] < 1.0 * (x[:,k].max()-x[:,k].min())\n",
    "        should_include = not (ci[0] < vmin[k] and ci[1] > vmax[k])\n",
    "        if should_include: \n",
    "            predicates.append(dict(\n",
    "                dim=k, interval=[max(ci[0],vmin[k]), min(ci[1], vmax[k])]\n",
    "            ))\n",
    "    return predicates\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## test, 2D dataset\n",
    "# data = np.random.rand(150,2)\n",
    "\n",
    "# target = (\n",
    "#     (0.3<data[:,0])*(data[:,0]<0.6)\n",
    "#     *(0<data[:,1])*(data[:,1]<0.5)\n",
    "# ).astype(np.int64)\n",
    "# target = ((0.3<data[:,0])*(data[:,0]<0.6)).astype(np.int64)\n",
    "\n",
    "# for i in range(10):\n",
    "#     p = predicate(data, target)\n",
    "#     display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf2f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc624b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
